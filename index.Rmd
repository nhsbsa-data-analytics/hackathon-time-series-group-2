---
title: "Hackathon November 2021 - Group 2"
output: 
  html_document:
    css: ["style.css", "colours.css"]
---

```{r, echo=FALSE}
options(scipen = 999)

library(openxlsx)
library(data.table)
library(lubridate)
library(ggplot2)
library(dplyr)
library(tidyr)
library(plotly)
library(rmarkdown)
library(stringr)
library(RColorBrewer)
library(gridExtra)
library(TSA)

```

### Introduction

We have been given the task of exploring time series analysis as part of a hackathon. We have been given access to 3 datasets:

1. Mortality data
2. [Data on COVID-19 (coronavirus) by Our World in Data](https://github.com/owid/covid-19-data/tree/master/public/data)
3. 

### Exploratory data analysis

###### 1 Mortalilty data

Read in data and format as time series.

```{r}
# Read in the correct sheet as a data.table
mortality_df <- 
  read.xlsx(
    xlsxFile = "Data/MortalityDataEngandWales_2011_2021.xlsx", 
    sheet = "TotalDeaths2011to2020"
  ) %>% 
  as.data.table()

# Name the table
setnames(mortality_df, 1:2, c("WE","Deaths"))

# Convert WE to a date
mortality_df[, WE := as.Date(WE, origin = as.Date("1899-12-30"))]

# Create the time series
mortality_ts <- ts(
  data = mortality_df$Deaths, 
  freq = 365.25/7, # https://stackoverflow.com/questions/22188660/r-time-series-modeling-on-weekly-data-using-ts-object
  start = decimal_date(ymd("2011-01-07"))
) 

```

The first confirmed cases of coronavirus in the UK were on January 29 [2020], when two Chinese nationals fell ill at the Staycity Aparthotel in York.

Plot the time series.

```{r, out.width="100%"}
p <- mortality_df %>%
  ggplot(aes(WE, Deaths)) + 
  geom_line() +
  scale_x_date(date_breaks = "1 year", date_labels = "%Y") +
  scale_y_continuous(labels = function(x) x/1e3) +
  geom_vline(xintercept = as.numeric(ymd("2020-01-29")), color="red", lty=2) +
  ylab("Deaths (thousands)") +
  theme_minimal() +
  theme(axis.title.x = element_blank())

ggplotly(p)
```

### Exploring correlations in mortality among age groups

Reading and preparing the data


```{r}

DT <- data.table()

for (i in 2011:2019) {
  
  t <- read.xlsx("Data/MortalityDataEngandWales_2011_2021.xlsx", sheet = paste0("TransposedData",i), cols = c(2, 17:32)) |> as.data.table()
  
  DT <- rbind(DT, t)
  
  rm(t)
  
}

setnames(DT, 1, "WE")
DT[, WE2 := dmy(WE)]
DT[is.na(WE2), WE2 := as.Date(as.numeric(WE), origin = as.Date("1899-12-30"))]

DT[, c(1,9,10) := NULL]

setnames(DT, 15, "WE")

setnames(DT, 1:7, paste0("M", names(DT)[1:7]))
setnames(DT, 8:14, paste0("F", names(DT)[8:14]))

DT <- melt(DT, id=15)

setnames(DT, 2, "AG")

DT[, Gender := str_extract(AG, "^.")]
DT[, AG := str_remove(AG, "^.")]

DT[, Gender := factor(Gender, levels = c("M","F"))]

DT[, AG := factor(AG, levels = c("Under.1.year", "01-14", "15-44", "45-64", "65-74", "75-84", "85+"),
                                  labels = c("<01", "01-14", "15-44", "45-64", "65-74", "75-84", "85+"))]

colm <- colorRampPalette(brewer.pal(9, "Blues"))(10)[4:10]
colf <- colorRampPalette(brewer.pal(9, "OrRd"))(10)[4:10]

DT

```

```{r}
ggplot(DT, aes(WE, value)) +
  geom_line(aes(color=paste(Gender, AG)))  +
  facet_wrap(~Gender) +
  ylab("Deaths\n") +
  ggtitle("Raw numbers of deaths") +
  scale_color_manual("Gender/AG", values = c(colf, colm)) +
  theme(axis.title.x = element_blank())
```

Normalize numbers of deaths to facilitate comparison.

```{r}
normalize <- function(x, na.rm = TRUE) {
  return((x- min(x)) /(max(x)-min(x)))
}

DT[, value_norm := normalize(value), by=.(Gender,AG)]

ggplot(DT, aes(WE, value_norm)) +
  geom_line(aes(color=paste(Gender, AG)))  +
  ylab("Normalized deaths\n") +
  ggtitle("Normalized numbers of deaths") +
  facet_wrap(~Gender) + 
  scale_color_manual("Gender/AG", values = c(colf, colm)) +
  theme(axis.title.x = element_blank())

```

Separate into facets.

```{r}
ggplot(DT, aes(WE, value_norm)) +
  geom_line(aes(color=paste(Gender, AG)))  +
  ylab("Normalized deaths\n") +
  ggtitle("Normalized numbers of deaths") +
  facet_grid(AG~Gender) + 
  scale_color_manual("Gender/AG", values = c(colf, colm)) +
  theme(axis.title.x = element_blank(),
        legend.position = 'none')
```

Calculate correlation coefficients (using raw or normalized data does not make a difference to the coefficients).
Correlations are strongest amongst older age groups in both genders.

```{r}
DTm <- DT[Gender=="M"] |> dcast(WE~AG, value.var = "value_norm")


Rm <- data.table()

for (j in names(DTm)[2:8]) {
  
  for (i in names(DTm)[2:8]) {
    
    r = cor.test(DTm[, get(i)], DTm[, get(j)])$estimate
    
    Rm <- rbind(Rm, data.table(x = i, y = j, r = r))
    
  }
  
}

Rm <- Rm[x > y]

ggplot(Rm, aes(x, y, fill = r)) +
  geom_tile() +
  geom_text(aes(label = broman::myround(r,2)), color = "white", size = 4) +
  coord_fixed() +
  scale_fill_gradient(low = colm[1], high = colm[7]) +
  theme(axis.title = element_blank(),
        panel.background = element_blank()) -> gm


DTf <- DT[Gender=="F"] |> dcast(WE~AG, value.var = "value_norm")


Rf <- data.table()

for (j in names(DTf)[2:8]) {
  
  for (i in names(DTf)[2:8]) {
    
    r = cor.test(DTf[, get(i)], DTf[, get(j)])$estimate
    
    Rf <- rbind(Rf, data.table(x = i, y = j, r = r))
    
  }
  
}

Rf <- Rf[x > y]

ggplot(Rf, aes(x, y, fill = r)) +
  geom_tile() +
  geom_text(aes(label = broman::myround(r,2)), color = "white", size = 4) +
  coord_fixed() +
  scale_fill_gradient(low = colf[1], high = colf[7]) +
  theme(axis.title = element_blank(),
        panel.background = element_blank()) -> gf

grid.arrange(gm, gf, nrow = 1)
```

The above correlations are at 0 lag. Let's explore the lag out of interest in one pair using the Cross-Correlation Function (CCF). 

```{r}
ccf(DTm[, `75-84`], DTm[, `85+`], main="M:75-84 vs M:85+", ylab="CCF")
```

The correlation is strongest at 0 lag. However, the strength of this correlation could be partly (even largely) due to both being driven by temporal effects (trend and/or seasonality). We can try to remove these temporal effects by removing seasonality and trend (by differencing) and pre-whitening.

```{r}
prewhiten(diff(diff(DTm[, `75-84`],52)), diff(diff(DTm[, `85+`],52)), main="M:75-84 vs M:85+", ylab="CCF")
```

The correlation at lag 0 is still strong, but weaker compared to the correlation at raw data. Presumably, this is because of other confounding effects beyond time (e.g. flu outbreaks).

If we do this on every pair of variables...

```{r message=FALSE, results=FALSE, fig.show='hide'}
Rm <- data.table()

for (j in names(DTm)[2:8]) {
  
  for (i in names(DTm)[2:8]) {
    
    ccf <- prewhiten(diff(diff(DTm[, get(i)],52)), diff(diff(DTm[, get(j)],52)))$ccf
    
    dt <- data.table(ccf = as.numeric(ccf$acf),lag = as.numeric(ccf$lag))
    
    r_0 = dt[lag==0, ccf]
    
    r_max = (prewhiten(diff(diff(DTm[, get(i)],52)), diff(diff(DTm[, get(j)],52)))$ccf$acf) |> max()
    
    Rm <- rbind(Rm, data.table(x = i, y = j, r_0 = r_0, r_max = r_max))
    
  }
  
}

ggplot(Rm, aes(x, y, fill = r_0)) +
  geom_tile() +
  geom_text(aes(label = broman::myround(r_0,2)), color = "white", size = 4) +
  coord_fixed() +
  scale_fill_gradient(low = colm[1], high = colm[7]) +
  theme(axis.title = element_blank(),
        panel.background = element_blank()) -> m1

ggplot(Rm, aes(x, y, fill = r_max)) +
  geom_tile() +
  geom_text(aes(label = broman::myround(r_max,2)), color = "white", size = 4) +
  coord_fixed() +
  scale_fill_gradient(low = colm[1], high = colm[7]) +
  theme(axis.title = element_blank(),
        panel.background = element_blank()) -> m2



Rf <- data.table()

for (j in names(DTf)[2:8]) {
  
  for (i in names(DTf)[2:8]) {
    
    ccf <- prewhiten(diff(diff(DTf[, get(i)],52)), diff(diff(DTf[, get(j)],52)))$ccf
    
    dt <- data.table(ccf = as.numeric(ccf$acf),lag = as.numeric(ccf$lag))
    
    r_0 = dt[lag==0, ccf]
    
    r_max = (prewhiten(diff(diff(DTf[, get(i)],52)), diff(diff(DTf[, get(j)],52)))$ccf$acf) |> max()
    
    Rf <- rbind(Rf, data.table(x = i, y = j, r_0 = r_0, r_max = r_max))
    
  }
  
}

ggplot(Rf, aes(x, y, fill = r_0)) +
  geom_tile() +
  geom_text(aes(label = broman::myround(r_0,2)), color = "white", size = 4) +
  coord_fixed() +
  scale_fill_gradient(low = colf[1], high = colf[7]) +
  theme(axis.title = element_blank(),
        panel.background = element_blank()) -> f1

ggplot(Rf, aes(x, y, fill = r_max)) +
  geom_tile() +
  geom_text(aes(label = broman::myround(r_max,2)), color = "white", size = 4) +
  coord_fixed() +
  scale_fill_gradient(low = colf[1], high = colf[7]) +
  theme(axis.title = element_blank(),
        panel.background = element_blank()) -> f2

```

```{r}
grid.arrange(m1, m2, f1, f2, nrow = 2)
```

A few things to note
- There are still fairly strong correlations among older age groups, but weaker compared to before differencing and pre-whitening.
- Coefficient matrices are not symmetrical: this is because pre-whitening function fits a TS model to the first series and then uses it to pre-whiten both series. So the order of series in a pair matters, but in this case the differences are tiny.
- The left sides show correlation coefficients at 0 lag, while the right sides show the maximum correlation coefficient at any lag. (Right coefficient can be larger than left, but not vice versa.) Here, it only makes a small difference in low-strength correlation pairs, which makes it negligible/unimportant.


###### 2. Data on COVID-19 (coronavirus) by Our World in Data

This data can be read in directly from GitHub using `{readr}`. The `col_types` have to be specified up front otherwise it doesn't load correctly.

```{r}
# Read in COVID data from GitHub with correct types
covid_df <- readr::read_csv(
  file = "https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv",
  col_types = "cccDdddddddddddddddddddddddddddddcddddddddddddddddddddddddddddddddd"
)

# Inspect it
paged_table(covid_df)
```

There are many columns and groups but we are going to focus on United Kingdom with a subset of columns.

```{r}
# Filter and subset columns
uk_covid_df <- covid_df %>% 
  filter(location == "United Kingdom") %>%
  # Rename some columns so they are either {col} or {col}_cumulative
  select(
    date, 
    cases = new_cases,
    cases_cumulative = total_cases,
    deaths = new_deaths, 
    deaths_cumulative = total_deaths, 
    #excess_mortality, # this is the % difference 
    excess_mortality_cumulative = excess_mortality_cumulative_absolute)

# Inspect it
paged_table(uk_covid_df)
```

We can see that the `excess_mortality_cumulative` is only updated weekly. So we forward `fill`.

```{r}
# Replace missing data from top to bottom
uk_covid_df <- uk_covid_df  %>%
  fill(excess_mortality_cumulative)

# Check it's worked
paged_table(uk_covid_df)
```

We also reverse engineer an `excess_mortality` column.

```{r}
# Reverse engineer the cumulative sum 
uk_covid_df <- uk_covid_df %>%
  # Replace all NAs with 0
  replace(is.na(.), 0) %>%
  mutate(
    excess_mortalilty = 
      excess_mortality_cumulative - lag(excess_mortality_cumulative)
  ) %>%
  # Catch the first NA that has become 0 because of the lag calc
  replace(is.na(.), 0) %>%
  dplyr::relocate(excess_mortalilty, .before = excess_mortality_cumulative)

# Inspect
paged_table(uk_covid_df)
```

Check the date range.

```{r,collapse=TRUE}
# Print off a summary of the dates
print(paste("Start date of cases:",uk_covid_df %>% summarise(min(date)) %>% pull()))
print(paste("Start date of deaths:", uk_covid_df %>% filter(deaths_cumulative > 0) %>% summarise(min(date)) %>% pull()))
print(paste("End date of cases:",uk_covid_df %>% summarise(max(date)) %>% pull()))
print(paste("End date of deaths:", uk_covid_df %>% filter(deaths_cumulative > 0) %>% summarise(max(date)) %>% pull()))
```

Quickly plot some of the cols (`{col}` on the right and `{col}_cumulative` on the right).

```{r, out.width="100%"}
# Chart the cols (not sure how you can have negative deaths)
p <- uk_covid_df %>% 
  pivot_longer(cols = -date, names_to = "measure", values_to = "count") %>%
  mutate(measure = as.factor(measure)) %>%
  ggplot(aes(x = date, y = count)) +
  geom_line() +
  facet_wrap(facets = ~measure, ncol = 2, scales = "free_y", shrink = FALSE) + 
  theme_minimal()

ggplotly(p)
```
