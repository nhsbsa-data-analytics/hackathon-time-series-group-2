---
title: "Hackathon November 2021 - Group 2"
output: 
  html_document:
    css: ["style.css", "colours.css"]
---

```{r, echo=FALSE}
library(dplyr)
library(ggplot2)
library(tidyr)
library(plotly)
library(rmarkdown)
```

### Introduction

We have been given the task of exploring time series analysis as part of a hackathon. We have been given access to 3 datasets:

1. [Data on COVID-19 (coronavirus) by Our World in Data](https://github.com/owid/covid-19-data/tree/master/public/data)
2.
3.

###### 1. Data on COVID-19 (coronavirus) by Our World in Data

This data can be read in directly from GitHub using `{readr}`. The `col_types` have to be specified up front otherwise it doesn't load correctly.

```{r}
# Read in COVID data from GitHub with correct types
covid_df <- readr::read_csv(
  file = "https://raw.githubusercontent.com/owid/covid-19-data/master/public/data/owid-covid-data.csv",
  col_types = "cccDdddddddddddddddddddddddddddddcddddddddddddddddddddddddddddddddd"
)

# Inspect it
paged_table(covid_df)
```

There are many columns and groups but we are going to focus on United Kingdom with a subset of columns.

```{r}
# Filter and subset columns
uk_covid_df <- covid_df %>% 
  filter(location == "United Kingdom") %>%
  # Rename some columns so they are either {col} or {col}_cumulative
  select(
    date, 
    cases = new_cases,
    cases_cumulative = total_cases,
    deaths = new_deaths, 
    deaths_cumulative = total_deaths, 
    #excess_mortality, # this is the % difference 
    excess_mortality_cumulative = excess_mortality_cumulative_absolute)

# Inspect it
paged_table(uk_covid_df)
```

We can see that the `excess_mortality_cumulative` is only updated weekly. So we forward `fill`.

```{r}
# Replace missing data from top to bottom
uk_covid_df <- uk_covid_df  %>%
  fill(excess_mortality_cumulative)

# Check it's worked
paged_table(uk_covid_df)
```

We also reverse engineer an `excess_mortality` column.

```{r}
# Reverse engineer the cumulative sum 
uk_covid_df <- uk_covid_df %>%
  # Replace all NAs with 0
  replace(is.na(.), 0) %>%
  mutate(
    excess_mortalilty = 
      excess_mortality_cumulative - lag(excess_mortality_cumulative)
  ) %>%
  # Catch the first NA that has become 0 because of the lag calc
  replace(is.na(.), 0) %>%
  dplyr::relocate(excess_mortalilty, .before = excess_mortality_cumulative)

# Inspect
paged_table(uk_covid_df)
```

Check the date range.

```{r,collapse=TRUE}
# Print off a summary of the dates
print(paste("Start date of cases:",uk_covid_df %>% summarise(min(date)) %>% pull()))
print(paste("Start date of deaths:", uk_covid_df %>% filter(deaths_cumulative > 0) %>% summarise(min(date)) %>% pull()))
print(paste("End date of cases:",uk_covid_df %>% summarise(max(date)) %>% pull()))
print(paste("End date of deaths:", uk_covid_df %>% filter(deaths_cumulative > 0) %>% summarise(max(date)) %>% pull()))
```

Quickly plot some of the cols (`{col}` on the right and `{col}_cumulative` on the right).

```{r, out.width="100%"}
# Chart the cols (not sure how you can have negative deaths)
p <- uk_covid_df %>% 
  pivot_longer(cols = -date, names_to = "measure", values_to = "count") %>%
  mutate(measure = as.factor(measure)) %>%
  ggplot(aes(x = date, y = count)) +
  geom_line() +
  facet_wrap(facets = ~measure, ncol = 2, scales = "free_y", shrink = FALSE) + 
  theme_minimal()

ggplotly(p)
```
